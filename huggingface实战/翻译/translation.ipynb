{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import evaluate\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"huggingface/models/opus-mt-de-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModel.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    de = [example['translation']['de'] for example in data]\n",
    "    en = [example['translation']['en'] for example in data]\n",
    "    data = tokenizer.batch_encode_plus(de, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        data['labels'] = tokenizer.batch_encode_plus(en, padding=True, truncation=True, max_length=128, return_tensors='pt')['input_ids']\n",
    "\n",
    "    data['decoder_input_ids'] = torch.full_like(data['labels'], tokenizer.get_vocab()['<pad>'])\n",
    "    data['decoder_input_ids'][:,1:] = data['labels'][:,:-1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"huggingface/datasets/wmt16/de-en\")\n",
    "train_dataloader = DataLoader(dataset['train'], batch_size=32, shuffle=True, \n",
    "                            drop_last=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(dataset['validation'], batch_size=32, shuffle=True, \n",
    "                            drop_last=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(dataset['test'], batch_size=32, shuffle=True, \n",
    "                            drop_last=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(path)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(512, tokenizer.vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, decoder_input_ids):\n",
    "        out = self.backbone(input_ids, attention_mask, decoder_input_ids)\n",
    "        out = out.last_hidden_state\n",
    "        out = self.fc(self.dropout(out))\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "model = Model()\n",
    "optimizer = AdamW([\n",
    "    {\"params\": model.backbone.parameters(), 'lr': 2e-5},\n",
    "    {\"params\": model.fc.parameters(), 'lr': 5e-4}\n",
    "])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            decoder_input_ids = data['decoder_input_ids'].to(device)\n",
    "            labels = data['labels'].to(device)\n",
    "            \n",
    "            out = model(input_ids, attention_mask, decoder_input_ids)\n",
    "            output_dim = out.shape[-1]\n",
    "            out = out.view(-1, output_dim)\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "            loss = criterion(out, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                loss_item = epoch_loss / (i + 1)\n",
    "                print('epoch:{}, idx:{}, loss:{}, PPL:{}'.format(epoch+1, i, loss_item, math.exp(loss_item)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, dataloader):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for data in dataloader:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        decoder_input_ids = data['decoder_input_ids'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    "        \n",
    "        out = model(input_ids, attention_mask, decoder_input_ids)\n",
    "        pred = tokenizer.batch_decode(out.argmax(dim=2), skip_special_tokens=True)\n",
    "        label = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        predictions.extend(pred)\n",
    "        references.extend(label)\n",
    "    \n",
    "    return predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(predictions, references):\n",
    "    references = [[i] for i in references]\n",
    "    metric = evaluate.load('bleu')\n",
    "    metric_out = metric.compute(predictions=predictions, references=references)\n",
    "    print(metric_out)\n",
    "    return metric_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, references = translate(model, valid_dataloader)\n",
    "valid_bleu = compute_bleu(predictions, references)\n",
    "predictions, references = translate(model, test_dataloader)\n",
    "test_bleu = compute_bleu(predictions, references)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'bleu': 0.29646412251432813, 'precisions': [0.6205257331394213, 0.3691747296528173, 0.2305722422994998, 0.14624795056123094], 'brevity_penalty': 1.0, 'length_ratio': 1.0033540237395187, 'translation_length': 46069, 'reference_length': 45915}\n",
    "\n",
    "{'bleu': 0.3444770324148899, 'precisions': [0.6559922215600791, 0.4178318802434611, 0.2764209361054416, 0.18585313371870385], 'brevity_penalty': 1.0, 'length_ratio': 1.0028623553095117, 'translation_length': 63766, 'reference_length': 63584}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"He is one of the most's moststt guyshuuse who who will have a lot of experience, played a under all conditions and against all attacks.\",\n",
       " \"He is one of the game's loveliest blokes, who will bring a wealth of experience having done it in all conditions and against all attacks.\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0], references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
